{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"forestfires.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>...</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "      <th>size_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>86.2</td>\n",
       "      <td>26.2</td>\n",
       "      <td>94.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>51</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>oct</td>\n",
       "      <td>tue</td>\n",
       "      <td>90.6</td>\n",
       "      <td>35.4</td>\n",
       "      <td>669.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oct</td>\n",
       "      <td>sat</td>\n",
       "      <td>90.6</td>\n",
       "      <td>43.7</td>\n",
       "      <td>686.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>14.6</td>\n",
       "      <td>33</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>91.7</td>\n",
       "      <td>33.3</td>\n",
       "      <td>77.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>97</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mar</td>\n",
       "      <td>sun</td>\n",
       "      <td>89.3</td>\n",
       "      <td>51.3</td>\n",
       "      <td>102.2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>11.4</td>\n",
       "      <td>99</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  month  day  FFMC   DMC     DC  ISI  temp  RH  wind  rain  ...  monthfeb  \\\n",
       "0   mar  fri  86.2  26.2   94.3  5.1   8.2  51   6.7   0.0  ...         0   \n",
       "1   oct  tue  90.6  35.4  669.1  6.7  18.0  33   0.9   0.0  ...         0   \n",
       "2   oct  sat  90.6  43.7  686.9  6.7  14.6  33   1.3   0.0  ...         0   \n",
       "3   mar  fri  91.7  33.3   77.5  9.0   8.3  97   4.0   0.2  ...         0   \n",
       "4   mar  sun  89.3  51.3  102.2  9.6  11.4  99   1.8   0.0  ...         0   \n",
       "\n",
       "   monthjan  monthjul  monthjun  monthmar  monthmay  monthnov  monthoct  \\\n",
       "0         0         0         0         1         0         0         0   \n",
       "1         0         0         0         0         0         0         1   \n",
       "2         0         0         0         0         0         0         1   \n",
       "3         0         0         0         1         0         0         0   \n",
       "4         0         0         0         1         0         0         0   \n",
       "\n",
       "   monthsep  size_category  \n",
       "0         0          small  \n",
       "1         0          small  \n",
       "2         0          small  \n",
       "3         0          small  \n",
       "4         0          small  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "month            0\n",
       "day              0\n",
       "FFMC             0\n",
       "DMC              0\n",
       "DC               0\n",
       "ISI              0\n",
       "temp             0\n",
       "RH               0\n",
       "wind             0\n",
       "rain             0\n",
       "area             0\n",
       "dayfri           0\n",
       "daymon           0\n",
       "daysat           0\n",
       "daysun           0\n",
       "daythu           0\n",
       "daytue           0\n",
       "daywed           0\n",
       "monthapr         0\n",
       "monthaug         0\n",
       "monthdec         0\n",
       "monthfeb         0\n",
       "monthjan         0\n",
       "monthjul         0\n",
       "monthjun         0\n",
       "monthmar         0\n",
       "monthmay         0\n",
       "monthnov         0\n",
       "monthoct         0\n",
       "monthsep         0\n",
       "size_category    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>area</th>\n",
       "      <th>dayfri</th>\n",
       "      <th>...</th>\n",
       "      <th>monthdec</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>90.644681</td>\n",
       "      <td>110.872340</td>\n",
       "      <td>547.940039</td>\n",
       "      <td>9.021663</td>\n",
       "      <td>18.889168</td>\n",
       "      <td>44.288201</td>\n",
       "      <td>4.017602</td>\n",
       "      <td>0.021663</td>\n",
       "      <td>12.847292</td>\n",
       "      <td>0.164410</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017408</td>\n",
       "      <td>0.038685</td>\n",
       "      <td>0.003868</td>\n",
       "      <td>0.061896</td>\n",
       "      <td>0.032882</td>\n",
       "      <td>0.104449</td>\n",
       "      <td>0.003868</td>\n",
       "      <td>0.001934</td>\n",
       "      <td>0.029014</td>\n",
       "      <td>0.332689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.520111</td>\n",
       "      <td>64.046482</td>\n",
       "      <td>248.066192</td>\n",
       "      <td>4.559477</td>\n",
       "      <td>5.806625</td>\n",
       "      <td>16.317469</td>\n",
       "      <td>1.791653</td>\n",
       "      <td>0.295959</td>\n",
       "      <td>63.655818</td>\n",
       "      <td>0.371006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130913</td>\n",
       "      <td>0.193029</td>\n",
       "      <td>0.062137</td>\n",
       "      <td>0.241199</td>\n",
       "      <td>0.178500</td>\n",
       "      <td>0.306138</td>\n",
       "      <td>0.062137</td>\n",
       "      <td>0.043980</td>\n",
       "      <td>0.168007</td>\n",
       "      <td>0.471632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.700000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>7.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>90.200000</td>\n",
       "      <td>68.600000</td>\n",
       "      <td>437.700000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>91.600000</td>\n",
       "      <td>108.300000</td>\n",
       "      <td>664.200000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>19.300000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>92.900000</td>\n",
       "      <td>142.400000</td>\n",
       "      <td>713.900000</td>\n",
       "      <td>10.800000</td>\n",
       "      <td>22.800000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.570000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>96.200000</td>\n",
       "      <td>291.300000</td>\n",
       "      <td>860.600000</td>\n",
       "      <td>56.100000</td>\n",
       "      <td>33.300000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>1090.840000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             FFMC         DMC          DC         ISI        temp          RH  \\\n",
       "count  517.000000  517.000000  517.000000  517.000000  517.000000  517.000000   \n",
       "mean    90.644681  110.872340  547.940039    9.021663   18.889168   44.288201   \n",
       "std      5.520111   64.046482  248.066192    4.559477    5.806625   16.317469   \n",
       "min     18.700000    1.100000    7.900000    0.000000    2.200000   15.000000   \n",
       "25%     90.200000   68.600000  437.700000    6.500000   15.500000   33.000000   \n",
       "50%     91.600000  108.300000  664.200000    8.400000   19.300000   42.000000   \n",
       "75%     92.900000  142.400000  713.900000   10.800000   22.800000   53.000000   \n",
       "max     96.200000  291.300000  860.600000   56.100000   33.300000  100.000000   \n",
       "\n",
       "             wind        rain         area      dayfri  ...    monthdec  \\\n",
       "count  517.000000  517.000000   517.000000  517.000000  ...  517.000000   \n",
       "mean     4.017602    0.021663    12.847292    0.164410  ...    0.017408   \n",
       "std      1.791653    0.295959    63.655818    0.371006  ...    0.130913   \n",
       "min      0.400000    0.000000     0.000000    0.000000  ...    0.000000   \n",
       "25%      2.700000    0.000000     0.000000    0.000000  ...    0.000000   \n",
       "50%      4.000000    0.000000     0.520000    0.000000  ...    0.000000   \n",
       "75%      4.900000    0.000000     6.570000    0.000000  ...    0.000000   \n",
       "max      9.400000    6.400000  1090.840000    1.000000  ...    1.000000   \n",
       "\n",
       "         monthfeb    monthjan    monthjul    monthjun    monthmar    monthmay  \\\n",
       "count  517.000000  517.000000  517.000000  517.000000  517.000000  517.000000   \n",
       "mean     0.038685    0.003868    0.061896    0.032882    0.104449    0.003868   \n",
       "std      0.193029    0.062137    0.241199    0.178500    0.306138    0.062137   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "         monthnov    monthoct    monthsep  \n",
       "count  517.000000  517.000000  517.000000  \n",
       "mean     0.001934    0.029014    0.332689  \n",
       "std      0.043980    0.168007    0.471632  \n",
       "min      0.000000    0.000000    0.000000  \n",
       "25%      0.000000    0.000000    0.000000  \n",
       "50%      0.000000    0.000000    0.000000  \n",
       "75%      0.000000    0.000000    1.000000  \n",
       "max      1.000000    1.000000    1.000000  \n",
       "\n",
       "[8 rows x 28 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#df['size_category'].value_counts().plot.pie()\n",
    "#plt.show()\n",
    "#print(df['size_category'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import seaborn as sns\n",
    "#sns.pairplot(df,hue='size_category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.iloc[:,:-1]\n",
    "y = df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>...</th>\n",
       "      <th>monthdec</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>37</td>\n",
       "      <td>41</td>\n",
       "      <td>29</td>\n",
       "      <td>12</td>\n",
       "      <td>34</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>56</td>\n",
       "      <td>49</td>\n",
       "      <td>144</td>\n",
       "      <td>42</td>\n",
       "      <td>85</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>156</td>\n",
       "      <td>42</td>\n",
       "      <td>55</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>48</td>\n",
       "      <td>33</td>\n",
       "      <td>64</td>\n",
       "      <td>13</td>\n",
       "      <td>72</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>46</td>\n",
       "      <td>66</td>\n",
       "      <td>46</td>\n",
       "      <td>68</td>\n",
       "      <td>30</td>\n",
       "      <td>73</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>71</td>\n",
       "      <td>141</td>\n",
       "      <td>7</td>\n",
       "      <td>172</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>71</td>\n",
       "      <td>141</td>\n",
       "      <td>7</td>\n",
       "      <td>123</td>\n",
       "      <td>54</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>71</td>\n",
       "      <td>141</td>\n",
       "      <td>7</td>\n",
       "      <td>116</td>\n",
       "      <td>53</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>92</td>\n",
       "      <td>168</td>\n",
       "      <td>122</td>\n",
       "      <td>80</td>\n",
       "      <td>156</td>\n",
       "      <td>25</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>4</td>\n",
       "      <td>34</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     month  day  FFMC  DMC   DC  ISI  temp  RH  wind  rain  ...  monthdec  \\\n",
       "0        7    0    28   37   41   29    12  34    14     0  ...         0   \n",
       "1       10    5    56   49  144   42    85  16     1     0  ...         0   \n",
       "2       10    2    56   56  156   42    55  16     2     0  ...         0   \n",
       "3        7    0    67   48   33   64    13  72     8     1  ...         0   \n",
       "4        7    3    46   66   46   68    30  73     3     0  ...         0   \n",
       "..     ...  ...   ...  ...  ...  ...   ...  ..   ...   ...  ...       ...   \n",
       "512      1    3     9   71  141    7   172  15     5     0  ...         0   \n",
       "513      1    3     9   71  141    7   123  54    12     0  ...         0   \n",
       "514      1    3     9   71  141    7   116  53    14     0  ...         0   \n",
       "515      1    2    92  168  122   80   156  25     8     0  ...         0   \n",
       "516      9    5     7    2   48    4    34  14     9     0  ...         0   \n",
       "\n",
       "     monthfeb  monthjan  monthjul  monthjun  monthmar  monthmay  monthnov  \\\n",
       "0           0         0         0         0         1         0         0   \n",
       "1           0         0         0         0         0         0         0   \n",
       "2           0         0         0         0         0         0         0   \n",
       "3           0         0         0         0         1         0         0   \n",
       "4           0         0         0         0         1         0         0   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "512         0         0         0         0         0         0         0   \n",
       "513         0         0         0         0         0         0         0   \n",
       "514         0         0         0         0         0         0         0   \n",
       "515         0         0         0         0         0         0         0   \n",
       "516         0         0         0         0         0         0         1   \n",
       "\n",
       "     monthoct  monthsep  \n",
       "0           0         0  \n",
       "1           1         0  \n",
       "2           1         0  \n",
       "3           0         0  \n",
       "4           0         0  \n",
       "..        ...       ...  \n",
       "512         0         0  \n",
       "513         0         0  \n",
       "514         0         0  \n",
       "515         0         0  \n",
       "516         0         0  \n",
       "\n",
       "[517 rows x 30 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder_x=LabelEncoder()\n",
    "x=x.apply(LabelEncoder().fit_transform)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     size_category\n",
       "0                1\n",
       "1                1\n",
       "2                1\n",
       "3                1\n",
       "4                1\n",
       "..             ...\n",
       "512              0\n",
       "513              0\n",
       "514              0\n",
       "515              1\n",
       "516              1\n",
       "\n",
       "[517 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.DataFrame(y)\n",
    "\n",
    "label_encoder_y = LabelEncoder()\n",
    "y = y.apply(LabelEncoder().fit_transform)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=30,  kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(8,  kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(1,  kernel_initializer='uniform', activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "35/35 [==============================] - 1s 8ms/step - loss: 0.6341 - accuracy: 0.7543 - val_loss: 0.5781 - val_accuracy: 0.6842\n",
      "Epoch 2/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4414 - accuracy: 0.8092 - val_loss: 0.4243 - val_accuracy: 0.7310\n",
      "Epoch 3/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2801 - accuracy: 0.9133 - val_loss: 0.2738 - val_accuracy: 0.8830\n",
      "Epoch 4/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1615 - accuracy: 0.9566 - val_loss: 0.1669 - val_accuracy: 0.9357\n",
      "Epoch 5/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1019 - accuracy: 0.9740 - val_loss: 0.1424 - val_accuracy: 0.9357\n",
      "Epoch 6/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0821 - accuracy: 0.9711 - val_loss: 0.1583 - val_accuracy: 0.9240\n",
      "Epoch 7/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0701 - accuracy: 0.9798 - val_loss: 0.1380 - val_accuracy: 0.9415\n",
      "Epoch 8/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0724 - accuracy: 0.9798 - val_loss: 0.1548 - val_accuracy: 0.9298\n",
      "Epoch 9/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0657 - accuracy: 0.9711 - val_loss: 0.1234 - val_accuracy: 0.9415\n",
      "Epoch 10/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0593 - accuracy: 0.9827 - val_loss: 0.1599 - val_accuracy: 0.9240\n",
      "Epoch 11/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0566 - accuracy: 0.9827 - val_loss: 0.1726 - val_accuracy: 0.9181\n",
      "Epoch 12/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0540 - accuracy: 0.9798 - val_loss: 0.1671 - val_accuracy: 0.9240\n",
      "Epoch 13/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0664 - accuracy: 0.9740 - val_loss: 0.1175 - val_accuracy: 0.9474\n",
      "Epoch 14/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0544 - accuracy: 0.9740 - val_loss: 0.1549 - val_accuracy: 0.9298\n",
      "Epoch 15/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0495 - accuracy: 0.9827 - val_loss: 0.1408 - val_accuracy: 0.9357\n",
      "Epoch 16/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0483 - accuracy: 0.9827 - val_loss: 0.1274 - val_accuracy: 0.9532\n",
      "Epoch 17/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0474 - accuracy: 0.9798 - val_loss: 0.1451 - val_accuracy: 0.9357\n",
      "Epoch 18/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0502 - accuracy: 0.9827 - val_loss: 0.1430 - val_accuracy: 0.9415\n",
      "Epoch 19/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0493 - accuracy: 0.9769 - val_loss: 0.1399 - val_accuracy: 0.9474\n",
      "Epoch 20/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0510 - accuracy: 0.9855 - val_loss: 0.1152 - val_accuracy: 0.9474\n",
      "Epoch 21/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0561 - accuracy: 0.9798 - val_loss: 0.1127 - val_accuracy: 0.9415\n",
      "Epoch 22/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0588 - accuracy: 0.9769 - val_loss: 0.1324 - val_accuracy: 0.9415\n",
      "Epoch 23/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0399 - accuracy: 0.9855 - val_loss: 0.2354 - val_accuracy: 0.8947\n",
      "Epoch 24/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0496 - accuracy: 0.9769 - val_loss: 0.2765 - val_accuracy: 0.8889\n",
      "Epoch 25/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0441 - accuracy: 0.9798 - val_loss: 0.1648 - val_accuracy: 0.9298\n",
      "Epoch 26/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0405 - accuracy: 0.9827 - val_loss: 0.1757 - val_accuracy: 0.9240\n",
      "Epoch 27/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0426 - accuracy: 0.9798 - val_loss: 0.2521 - val_accuracy: 0.8889\n",
      "Epoch 28/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0534 - accuracy: 0.9798 - val_loss: 0.2440 - val_accuracy: 0.8889\n",
      "Epoch 29/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0462 - accuracy: 0.9740 - val_loss: 0.1162 - val_accuracy: 0.9357\n",
      "Epoch 30/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0366 - accuracy: 0.9827 - val_loss: 0.1914 - val_accuracy: 0.9240\n",
      "Epoch 31/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0445 - accuracy: 0.9827 - val_loss: 0.1168 - val_accuracy: 0.9298\n",
      "Epoch 32/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0423 - accuracy: 0.9855 - val_loss: 0.1212 - val_accuracy: 0.9357\n",
      "Epoch 33/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0455 - accuracy: 0.9798 - val_loss: 0.1193 - val_accuracy: 0.9240\n",
      "Epoch 34/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0390 - accuracy: 0.9740 - val_loss: 0.1305 - val_accuracy: 0.9357\n",
      "Epoch 35/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0350 - accuracy: 0.9798 - val_loss: 0.1569 - val_accuracy: 0.9415\n",
      "Epoch 36/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0333 - accuracy: 0.9855 - val_loss: 0.2050 - val_accuracy: 0.9240\n",
      "Epoch 37/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0378 - accuracy: 0.9827 - val_loss: 0.1467 - val_accuracy: 0.9357\n",
      "Epoch 38/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0375 - accuracy: 0.9798 - val_loss: 0.1885 - val_accuracy: 0.9298\n",
      "Epoch 39/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0405 - accuracy: 0.9827 - val_loss: 0.1239 - val_accuracy: 0.9298\n",
      "Epoch 40/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0421 - accuracy: 0.9769 - val_loss: 0.1252 - val_accuracy: 0.9298\n",
      "Epoch 41/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0443 - accuracy: 0.9827 - val_loss: 0.1354 - val_accuracy: 0.9357\n",
      "Epoch 42/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0354 - accuracy: 0.9827 - val_loss: 0.1487 - val_accuracy: 0.9357\n",
      "Epoch 43/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0336 - accuracy: 0.9798 - val_loss: 0.1649 - val_accuracy: 0.9357\n",
      "Epoch 44/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0400 - accuracy: 0.9769 - val_loss: 0.2986 - val_accuracy: 0.9123\n",
      "Epoch 45/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0398 - accuracy: 0.9798 - val_loss: 0.3775 - val_accuracy: 0.9064\n",
      "Epoch 46/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0457 - accuracy: 0.9884 - val_loss: 0.1557 - val_accuracy: 0.9357\n",
      "Epoch 47/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0308 - accuracy: 0.9855 - val_loss: 0.1749 - val_accuracy: 0.9415\n",
      "Epoch 48/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0342 - accuracy: 0.9884 - val_loss: 0.1287 - val_accuracy: 0.9240\n",
      "Epoch 49/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0384 - accuracy: 0.9827 - val_loss: 0.1859 - val_accuracy: 0.9474\n",
      "Epoch 50/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0247 - accuracy: 0.9913 - val_loss: 0.1432 - val_accuracy: 0.9415\n",
      "Epoch 51/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0272 - accuracy: 0.9855 - val_loss: 0.1778 - val_accuracy: 0.9415\n",
      "Epoch 52/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0222 - accuracy: 0.9942 - val_loss: 0.1909 - val_accuracy: 0.9415\n",
      "Epoch 53/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0221 - accuracy: 0.9942 - val_loss: 0.2064 - val_accuracy: 0.9415\n",
      "Epoch 54/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0221 - accuracy: 0.9913 - val_loss: 0.4357 - val_accuracy: 0.9064\n",
      "Epoch 55/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0466 - accuracy: 0.9798 - val_loss: 0.2847 - val_accuracy: 0.9357\n",
      "Epoch 56/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0252 - accuracy: 0.9884 - val_loss: 0.1767 - val_accuracy: 0.9474\n",
      "Epoch 57/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0273 - accuracy: 0.9913 - val_loss: 0.2639 - val_accuracy: 0.9357\n",
      "Epoch 58/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0325 - accuracy: 0.9884 - val_loss: 0.2783 - val_accuracy: 0.9357\n",
      "Epoch 59/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0259 - accuracy: 0.9913 - val_loss: 0.2238 - val_accuracy: 0.9415\n",
      "Epoch 60/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0215 - accuracy: 0.9913 - val_loss: 0.1772 - val_accuracy: 0.9415\n",
      "Epoch 61/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0244 - accuracy: 0.9884 - val_loss: 0.2012 - val_accuracy: 0.9474\n",
      "Epoch 62/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0179 - accuracy: 0.9942 - val_loss: 0.5358 - val_accuracy: 0.8947\n",
      "Epoch 63/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0323 - accuracy: 0.9855 - val_loss: 0.2394 - val_accuracy: 0.9298\n",
      "Epoch 64/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0209 - accuracy: 0.9942 - val_loss: 0.1886 - val_accuracy: 0.9415\n",
      "Epoch 65/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0228 - accuracy: 0.9913 - val_loss: 0.3355 - val_accuracy: 0.9357\n",
      "Epoch 66/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0319 - accuracy: 0.9884 - val_loss: 0.2296 - val_accuracy: 0.9415\n",
      "Epoch 67/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0203 - accuracy: 0.9884 - val_loss: 0.2139 - val_accuracy: 0.9474\n",
      "Epoch 68/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0273 - accuracy: 0.9913 - val_loss: 0.2184 - val_accuracy: 0.9474\n",
      "Epoch 69/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0198 - accuracy: 0.9942 - val_loss: 0.2848 - val_accuracy: 0.9298\n",
      "Epoch 70/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0187 - accuracy: 0.9942 - val_loss: 0.2203 - val_accuracy: 0.9474\n",
      "Epoch 71/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0258 - accuracy: 0.9913 - val_loss: 0.1784 - val_accuracy: 0.9240\n",
      "Epoch 72/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0375 - accuracy: 0.9855 - val_loss: 0.1962 - val_accuracy: 0.9415\n",
      "Epoch 73/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0408 - accuracy: 0.9827 - val_loss: 0.2332 - val_accuracy: 0.9415\n",
      "Epoch 74/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0181 - accuracy: 0.9971 - val_loss: 0.2750 - val_accuracy: 0.9357\n",
      "Epoch 75/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0185 - accuracy: 0.9913 - val_loss: 0.2148 - val_accuracy: 0.9474\n",
      "Epoch 76/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0260 - accuracy: 0.9942 - val_loss: 0.1894 - val_accuracy: 0.9240\n",
      "Epoch 77/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0267 - accuracy: 0.9942 - val_loss: 0.2625 - val_accuracy: 0.9357\n",
      "Epoch 78/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0224 - accuracy: 0.9913 - val_loss: 0.2809 - val_accuracy: 0.9415\n",
      "Epoch 79/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0231 - accuracy: 0.9942 - val_loss: 0.2332 - val_accuracy: 0.9474\n",
      "Epoch 80/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0221 - accuracy: 0.9942 - val_loss: 0.2407 - val_accuracy: 0.9474\n",
      "Epoch 81/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0204 - accuracy: 0.9971 - val_loss: 0.2328 - val_accuracy: 0.9474\n",
      "Epoch 82/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0204 - accuracy: 0.9942 - val_loss: 0.4101 - val_accuracy: 0.9240\n",
      "Epoch 83/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0343 - accuracy: 0.9884 - val_loss: 0.3971 - val_accuracy: 0.9240\n",
      "Epoch 84/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0283 - accuracy: 0.9827 - val_loss: 0.2134 - val_accuracy: 0.9415\n",
      "Epoch 85/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0207 - accuracy: 0.9942 - val_loss: 0.2460 - val_accuracy: 0.9474\n",
      "Epoch 86/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0200 - accuracy: 0.9942 - val_loss: 0.2246 - val_accuracy: 0.9474\n",
      "Epoch 87/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0185 - accuracy: 0.9942 - val_loss: 0.2676 - val_accuracy: 0.9357\n",
      "Epoch 88/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0180 - accuracy: 0.9942 - val_loss: 0.3225 - val_accuracy: 0.9298\n",
      "Epoch 89/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0186 - accuracy: 0.9884 - val_loss: 0.2497 - val_accuracy: 0.9474\n",
      "Epoch 90/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0230 - accuracy: 0.9942 - val_loss: 0.2342 - val_accuracy: 0.9474\n",
      "Epoch 91/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0229 - accuracy: 0.9884 - val_loss: 0.2133 - val_accuracy: 0.9357\n",
      "Epoch 92/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0140 - accuracy: 0.9942 - val_loss: 0.4175 - val_accuracy: 0.9298\n",
      "Epoch 93/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0196 - accuracy: 0.9913 - val_loss: 0.2684 - val_accuracy: 0.9415\n",
      "Epoch 94/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0177 - accuracy: 0.9942 - val_loss: 0.2921 - val_accuracy: 0.9298\n",
      "Epoch 95/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0262 - accuracy: 0.9942 - val_loss: 0.4208 - val_accuracy: 0.9298\n",
      "Epoch 96/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0261 - accuracy: 0.9913 - val_loss: 0.2827 - val_accuracy: 0.9357\n",
      "Epoch 97/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0157 - accuracy: 0.9942 - val_loss: 0.2587 - val_accuracy: 0.9474\n",
      "Epoch 98/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0188 - accuracy: 0.9942 - val_loss: 0.2893 - val_accuracy: 0.9357\n",
      "Epoch 99/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0201 - accuracy: 0.9942 - val_loss: 0.3909 - val_accuracy: 0.9357\n",
      "Epoch 100/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0209 - accuracy: 0.9913 - val_loss: 0.2337 - val_accuracy: 0.9474\n",
      "Epoch 101/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0307 - accuracy: 0.9855 - val_loss: 0.2162 - val_accuracy: 0.9298\n",
      "Epoch 102/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0278 - accuracy: 0.9884 - val_loss: 0.2664 - val_accuracy: 0.9474\n",
      "Epoch 103/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0191 - accuracy: 0.9942 - val_loss: 0.2435 - val_accuracy: 0.9474\n",
      "Epoch 104/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0322 - accuracy: 0.9884 - val_loss: 0.2161 - val_accuracy: 0.9298\n",
      "Epoch 105/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0297 - accuracy: 0.9913 - val_loss: 0.2255 - val_accuracy: 0.9474\n",
      "Epoch 106/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0206 - accuracy: 0.9942 - val_loss: 0.2624 - val_accuracy: 0.9474\n",
      "Epoch 107/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0198 - accuracy: 0.9942 - val_loss: 0.2396 - val_accuracy: 0.9474\n",
      "Epoch 108/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0167 - accuracy: 0.9913 - val_loss: 0.2208 - val_accuracy: 0.9357\n",
      "Epoch 109/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0245 - accuracy: 0.9942 - val_loss: 0.2315 - val_accuracy: 0.9474\n",
      "Epoch 110/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0161 - accuracy: 0.9942 - val_loss: 0.4384 - val_accuracy: 0.9298\n",
      "Epoch 111/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0290 - accuracy: 0.9913 - val_loss: 0.2292 - val_accuracy: 0.9415\n",
      "Epoch 112/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0243 - accuracy: 0.9913 - val_loss: 0.2145 - val_accuracy: 0.9298\n",
      "Epoch 113/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0193 - accuracy: 0.9942 - val_loss: 0.3382 - val_accuracy: 0.9357\n",
      "Epoch 114/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0165 - accuracy: 0.9942 - val_loss: 0.2754 - val_accuracy: 0.9474\n",
      "Epoch 115/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0180 - accuracy: 0.9971 - val_loss: 0.3512 - val_accuracy: 0.9298\n",
      "Epoch 116/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0291 - accuracy: 0.9913 - val_loss: 0.2562 - val_accuracy: 0.9474\n",
      "Epoch 117/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0175 - accuracy: 0.9942 - val_loss: 0.2893 - val_accuracy: 0.9357\n",
      "Epoch 118/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0162 - accuracy: 0.9942 - val_loss: 0.2503 - val_accuracy: 0.9474\n",
      "Epoch 119/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0314 - accuracy: 0.9884 - val_loss: 0.2422 - val_accuracy: 0.9415\n",
      "Epoch 120/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0197 - accuracy: 0.9942 - val_loss: 0.2594 - val_accuracy: 0.9474\n",
      "Epoch 121/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0160 - accuracy: 0.9913 - val_loss: 0.2946 - val_accuracy: 0.9357\n",
      "Epoch 122/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0205 - accuracy: 0.9913 - val_loss: 0.2578 - val_accuracy: 0.9474\n",
      "Epoch 123/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0170 - accuracy: 0.9913 - val_loss: 0.2895 - val_accuracy: 0.9357\n",
      "Epoch 124/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0279 - accuracy: 0.9884 - val_loss: 0.2504 - val_accuracy: 0.9474\n",
      "Epoch 125/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0197 - accuracy: 0.9913 - val_loss: 0.3040 - val_accuracy: 0.9357\n",
      "Epoch 126/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0206 - accuracy: 0.9913 - val_loss: 0.3523 - val_accuracy: 0.9298\n",
      "Epoch 127/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0181 - accuracy: 0.9913 - val_loss: 0.2729 - val_accuracy: 0.9415\n",
      "Epoch 128/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.0159 - accuracy: 0.9971 - val_loss: 0.3437 - val_accuracy: 0.9298\n",
      "Epoch 129/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0235 - accuracy: 0.9884 - val_loss: 0.2886 - val_accuracy: 0.9357\n",
      "Epoch 130/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0269 - accuracy: 0.9884 - val_loss: 0.3061 - val_accuracy: 0.9357\n",
      "Epoch 131/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0200 - accuracy: 0.9913 - val_loss: 0.2373 - val_accuracy: 0.9415\n",
      "Epoch 132/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0198 - accuracy: 0.9913 - val_loss: 0.2729 - val_accuracy: 0.9415\n",
      "Epoch 133/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0165 - accuracy: 0.9913 - val_loss: 0.2648 - val_accuracy: 0.9474\n",
      "Epoch 134/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0151 - accuracy: 0.9942 - val_loss: 0.3040 - val_accuracy: 0.9357\n",
      "Epoch 135/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0252 - accuracy: 0.9913 - val_loss: 0.2870 - val_accuracy: 0.9415\n",
      "Epoch 136/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0161 - accuracy: 0.9913 - val_loss: 0.2405 - val_accuracy: 0.9415\n",
      "Epoch 137/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0184 - accuracy: 0.9884 - val_loss: 0.3274 - val_accuracy: 0.9298\n",
      "Epoch 138/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0170 - accuracy: 0.9942 - val_loss: 0.3194 - val_accuracy: 0.9357\n",
      "Epoch 139/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0475 - accuracy: 0.9884 - val_loss: 0.2295 - val_accuracy: 0.9357\n",
      "Epoch 140/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0165 - accuracy: 0.9971 - val_loss: 0.2612 - val_accuracy: 0.9474\n",
      "Epoch 141/150\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0193 - accuracy: 0.9971 - val_loss: 0.3398 - val_accuracy: 0.9298\n",
      "Epoch 142/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0161 - accuracy: 0.9971 - val_loss: 0.2568 - val_accuracy: 0.9474\n",
      "Epoch 143/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0180 - accuracy: 0.9913 - val_loss: 0.3023 - val_accuracy: 0.9357\n",
      "Epoch 144/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0131 - accuracy: 0.9942 - val_loss: 0.2983 - val_accuracy: 0.9357\n",
      "Epoch 145/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0179 - accuracy: 0.9942 - val_loss: 0.2923 - val_accuracy: 0.9357\n",
      "Epoch 146/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0200 - accuracy: 0.9913 - val_loss: 0.2826 - val_accuracy: 0.9415\n",
      "Epoch 147/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0213 - accuracy: 0.9884 - val_loss: 0.2051 - val_accuracy: 0.9240\n",
      "Epoch 148/150\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.0250 - accuracy: 0.9971 - val_loss: 0.3115 - val_accuracy: 0.9415\n",
      "Epoch 149/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0136 - accuracy: 0.9971 - val_loss: 0.2892 - val_accuracy: 0.9415\n",
      "Epoch 150/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0125 - accuracy: 0.9942 - val_loss: 0.3116 - val_accuracy: 0.9415\n"
     ]
    }
   ],
   "source": [
    "history= model.fit(x, y, validation_split=0.33, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 561us/step - loss: 0.1104 - accuracy: 0.9768\n",
      "accuracy: 97.68%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x, y)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = StandardScaler()\n",
    "a.fit(x)\n",
    "X_standardized = a.transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-4.874674e-17</td>\n",
       "      <td>5.110891e-17</td>\n",
       "      <td>-9.019220e-17</td>\n",
       "      <td>2.594099e-16</td>\n",
       "      <td>6.442300e-17</td>\n",
       "      <td>-8.718579e-17</td>\n",
       "      <td>-7.816657e-17</td>\n",
       "      <td>6.485249e-17</td>\n",
       "      <td>4.724353e-18</td>\n",
       "      <td>-4.790924e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>7.179943e-16</td>\n",
       "      <td>-1.933764e-16</td>\n",
       "      <td>-2.260174e-17</td>\n",
       "      <td>1.352883e-17</td>\n",
       "      <td>1.169277e-16</td>\n",
       "      <td>2.265542e-16</td>\n",
       "      <td>-2.596515e-16</td>\n",
       "      <td>1.443075e-16</td>\n",
       "      <td>6.253326e-16</td>\n",
       "      <td>4.024290e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.317959e+00</td>\n",
       "      <td>-1.423121e+00</td>\n",
       "      <td>-2.755520e+00</td>\n",
       "      <td>-2.134531e+00</td>\n",
       "      <td>-2.119754e+00</td>\n",
       "      <td>-2.133725e+00</td>\n",
       "      <td>-2.036890e+00</td>\n",
       "      <td>-1.713964e+00</td>\n",
       "      <td>-2.004018e+00</td>\n",
       "      <td>-1.100649e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.331035e-01</td>\n",
       "      <td>-2.006027e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-2.568645e-01</td>\n",
       "      <td>-1.843909e-01</td>\n",
       "      <td>-3.415123e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-4.402255e-02</td>\n",
       "      <td>-1.728597e-01</td>\n",
       "      <td>-7.060812e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.089076e+00</td>\n",
       "      <td>-9.031536e-01</td>\n",
       "      <td>-5.025653e-01</td>\n",
       "      <td>-8.010724e-01</td>\n",
       "      <td>-7.605602e-01</td>\n",
       "      <td>-6.928003e-01</td>\n",
       "      <td>-7.181571e-01</td>\n",
       "      <td>-7.060079e-01</td>\n",
       "      <td>-7.499909e-01</td>\n",
       "      <td>-1.100649e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.331035e-01</td>\n",
       "      <td>-2.006027e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-2.568645e-01</td>\n",
       "      <td>-1.843909e-01</td>\n",
       "      <td>-3.415123e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-4.402255e-02</td>\n",
       "      <td>-1.728597e-01</td>\n",
       "      <td>-7.060812e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.533922e-02</td>\n",
       "      <td>1.367805e-01</td>\n",
       "      <td>1.039993e-01</td>\n",
       "      <td>1.234588e-01</td>\n",
       "      <td>1.959092e-01</td>\n",
       "      <td>-4.438437e-02</td>\n",
       "      <td>4.755898e-02</td>\n",
       "      <td>-1.390326e-01</td>\n",
       "      <td>2.425585e-03</td>\n",
       "      <td>-1.100649e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.331035e-01</td>\n",
       "      <td>-2.006027e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-2.568645e-01</td>\n",
       "      <td>-1.843909e-01</td>\n",
       "      <td>-3.415123e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-4.402255e-02</td>\n",
       "      <td>-1.728597e-01</td>\n",
       "      <td>-7.060812e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.199754e+00</td>\n",
       "      <td>6.567476e-01</td>\n",
       "      <td>6.672378e-01</td>\n",
       "      <td>8.168572e-01</td>\n",
       "      <td>7.999952e-01</td>\n",
       "      <td>6.400547e-01</td>\n",
       "      <td>7.494654e-01</td>\n",
       "      <td>5.539372e-01</td>\n",
       "      <td>5.040366e-01</td>\n",
       "      <td>-1.100649e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.331035e-01</td>\n",
       "      <td>-2.006027e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-2.568645e-01</td>\n",
       "      <td>-1.843909e-01</td>\n",
       "      <td>-3.415123e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-4.402255e-02</td>\n",
       "      <td>-1.728597e-01</td>\n",
       "      <td>1.416268e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.199754e+00</td>\n",
       "      <td>1.696682e+00</td>\n",
       "      <td>1.793715e+00</td>\n",
       "      <td>1.670271e+00</td>\n",
       "      <td>1.538322e+00</td>\n",
       "      <td>2.117002e+00</td>\n",
       "      <td>2.025659e+00</td>\n",
       "      <td>2.947833e+00</td>\n",
       "      <td>3.012092e+00</td>\n",
       "      <td>1.354679e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>7.512952e+00</td>\n",
       "      <td>4.984977e+00</td>\n",
       "      <td>1.604681e+01</td>\n",
       "      <td>3.893103e+00</td>\n",
       "      <td>5.423261e+00</td>\n",
       "      <td>2.928152e+00</td>\n",
       "      <td>1.604681e+01</td>\n",
       "      <td>2.271563e+01</td>\n",
       "      <td>5.785038e+00</td>\n",
       "      <td>1.416268e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0             1             2             3             4   \\\n",
       "count  5.170000e+02  5.170000e+02  5.170000e+02  5.170000e+02  5.170000e+02   \n",
       "mean  -4.874674e-17  5.110891e-17 -9.019220e-17  2.594099e-16  6.442300e-17   \n",
       "std    1.000969e+00  1.000969e+00  1.000969e+00  1.000969e+00  1.000969e+00   \n",
       "min   -1.317959e+00 -1.423121e+00 -2.755520e+00 -2.134531e+00 -2.119754e+00   \n",
       "25%   -1.089076e+00 -9.031536e-01 -5.025653e-01 -8.010724e-01 -7.605602e-01   \n",
       "50%    5.533922e-02  1.367805e-01  1.039993e-01  1.234588e-01  1.959092e-01   \n",
       "75%    1.199754e+00  6.567476e-01  6.672378e-01  8.168572e-01  7.999952e-01   \n",
       "max    1.199754e+00  1.696682e+00  1.793715e+00  1.670271e+00  1.538322e+00   \n",
       "\n",
       "                 5             6             7             8             9   \\\n",
       "count  5.170000e+02  5.170000e+02  5.170000e+02  5.170000e+02  5.170000e+02   \n",
       "mean  -8.718579e-17 -7.816657e-17  6.485249e-17  4.724353e-18 -4.790924e-16   \n",
       "std    1.000969e+00  1.000969e+00  1.000969e+00  1.000969e+00  1.000969e+00   \n",
       "min   -2.133725e+00 -2.036890e+00 -1.713964e+00 -2.004018e+00 -1.100649e-01   \n",
       "25%   -6.928003e-01 -7.181571e-01 -7.060079e-01 -7.499909e-01 -1.100649e-01   \n",
       "50%   -4.438437e-02  4.755898e-02 -1.390326e-01  2.425585e-03 -1.100649e-01   \n",
       "75%    6.400547e-01  7.494654e-01  5.539372e-01  5.040366e-01 -1.100649e-01   \n",
       "max    2.117002e+00  2.025659e+00  2.947833e+00  3.012092e+00  1.354679e+01   \n",
       "\n",
       "       ...            20            21            22            23  \\\n",
       "count  ...  5.170000e+02  5.170000e+02  5.170000e+02  5.170000e+02   \n",
       "mean   ...  7.179943e-16 -1.933764e-16 -2.260174e-17  1.352883e-17   \n",
       "std    ...  1.000969e+00  1.000969e+00  1.000969e+00  1.000969e+00   \n",
       "min    ... -1.331035e-01 -2.006027e-01 -6.231770e-02 -2.568645e-01   \n",
       "25%    ... -1.331035e-01 -2.006027e-01 -6.231770e-02 -2.568645e-01   \n",
       "50%    ... -1.331035e-01 -2.006027e-01 -6.231770e-02 -2.568645e-01   \n",
       "75%    ... -1.331035e-01 -2.006027e-01 -6.231770e-02 -2.568645e-01   \n",
       "max    ...  7.512952e+00  4.984977e+00  1.604681e+01  3.893103e+00   \n",
       "\n",
       "                 24            25            26            27            28  \\\n",
       "count  5.170000e+02  5.170000e+02  5.170000e+02  5.170000e+02  5.170000e+02   \n",
       "mean   1.169277e-16  2.265542e-16 -2.596515e-16  1.443075e-16  6.253326e-16   \n",
       "std    1.000969e+00  1.000969e+00  1.000969e+00  1.000969e+00  1.000969e+00   \n",
       "min   -1.843909e-01 -3.415123e-01 -6.231770e-02 -4.402255e-02 -1.728597e-01   \n",
       "25%   -1.843909e-01 -3.415123e-01 -6.231770e-02 -4.402255e-02 -1.728597e-01   \n",
       "50%   -1.843909e-01 -3.415123e-01 -6.231770e-02 -4.402255e-02 -1.728597e-01   \n",
       "75%   -1.843909e-01 -3.415123e-01 -6.231770e-02 -4.402255e-02 -1.728597e-01   \n",
       "max    5.423261e+00  2.928152e+00  1.604681e+01  2.271563e+01  5.785038e+00   \n",
       "\n",
       "                 29  \n",
       "count  5.170000e+02  \n",
       "mean   4.024290e-16  \n",
       "std    1.000969e+00  \n",
       "min   -7.060812e-01  \n",
       "25%   -7.060812e-01  \n",
       "50%   -7.060812e-01  \n",
       "75%    1.416268e+00  \n",
       "max    1.416268e+00  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_standardized).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-20-7befaba14f10>:10: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  model = KerasClassifier(build_fn = create_model,verbose = 0)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\Users\\sande\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV] batch_size=10, epochs=10 ........................................\n",
      "[CV] ............ batch_size=10, epochs=10, score=1.000, total=   0.8s\n",
      "[CV] batch_size=10, epochs=10 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ batch_size=10, epochs=10, score=0.904, total=   0.9s\n",
      "[CV] batch_size=10, epochs=10 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    1.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ batch_size=10, epochs=10, score=0.981, total=   0.9s\n",
      "[CV] batch_size=10, epochs=10 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    2.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ batch_size=10, epochs=10, score=0.932, total=   1.0s\n",
      "[CV] batch_size=10, epochs=10 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    3.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ batch_size=10, epochs=10, score=0.951, total=   0.9s\n",
      "[CV] batch_size=10, epochs=50 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    4.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ batch_size=10, epochs=50, score=1.000, total=   2.1s\n",
      "[CV] batch_size=10, epochs=50 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    6.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ batch_size=10, epochs=50, score=0.933, total=   2.3s\n",
      "[CV] batch_size=10, epochs=50 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    8.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ batch_size=10, epochs=50, score=0.981, total=   2.0s\n",
      "[CV] batch_size=10, epochs=50 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   10.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ batch_size=10, epochs=50, score=0.942, total=   2.0s\n",
      "[CV] batch_size=10, epochs=50 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   12.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ batch_size=10, epochs=50, score=0.942, total=   2.1s\n",
      "[CV] batch_size=10, epochs=100 .......................................\n",
      "[CV] ........... batch_size=10, epochs=100, score=1.000, total=   3.5s\n",
      "[CV] batch_size=10, epochs=100 .......................................\n",
      "[CV] ........... batch_size=10, epochs=100, score=0.971, total=   3.6s\n",
      "[CV] batch_size=10, epochs=100 .......................................\n",
      "[CV] ........... batch_size=10, epochs=100, score=0.981, total=   3.5s\n",
      "[CV] batch_size=10, epochs=100 .......................................\n",
      "[CV] ........... batch_size=10, epochs=100, score=0.961, total=   3.3s\n",
      "[CV] batch_size=10, epochs=100 .......................................\n",
      "[CV] ........... batch_size=10, epochs=100, score=0.913, total=   3.4s\n",
      "[CV] batch_size=20, epochs=10 ........................................\n",
      "[CV] ............ batch_size=20, epochs=10, score=1.000, total=   0.6s\n",
      "[CV] batch_size=20, epochs=10 ........................................\n",
      "[CV] ............ batch_size=20, epochs=10, score=0.962, total=   0.7s\n",
      "[CV] batch_size=20, epochs=10 ........................................\n",
      "[CV] ............ batch_size=20, epochs=10, score=0.981, total=   0.9s\n",
      "[CV] batch_size=20, epochs=10 ........................................\n",
      "[CV] ............ batch_size=20, epochs=10, score=0.932, total=   0.6s\n",
      "[CV] batch_size=20, epochs=10 ........................................\n",
      "[CV] ............ batch_size=20, epochs=10, score=0.942, total=   0.7s\n",
      "[CV] batch_size=20, epochs=50 ........................................\n",
      "[CV] ............ batch_size=20, epochs=50, score=1.000, total=   1.2s\n",
      "[CV] batch_size=20, epochs=50 ........................................\n",
      "[CV] ............ batch_size=20, epochs=50, score=0.952, total=   1.2s\n",
      "[CV] batch_size=20, epochs=50 ........................................\n",
      "[CV] ............ batch_size=20, epochs=50, score=0.971, total=   1.2s\n",
      "[CV] batch_size=20, epochs=50 ........................................\n",
      "[CV] ............ batch_size=20, epochs=50, score=0.942, total=   1.4s\n",
      "[CV] batch_size=20, epochs=50 ........................................\n",
      "[CV] ............ batch_size=20, epochs=50, score=0.932, total=   1.2s\n",
      "[CV] batch_size=20, epochs=100 .......................................\n",
      "[CV] ........... batch_size=20, epochs=100, score=1.000, total=   1.9s\n",
      "[CV] batch_size=20, epochs=100 .......................................\n",
      "[CV] ........... batch_size=20, epochs=100, score=0.962, total=   2.1s\n",
      "[CV] batch_size=20, epochs=100 .......................................\n",
      "[CV] ........... batch_size=20, epochs=100, score=0.981, total=   1.9s\n",
      "[CV] batch_size=20, epochs=100 .......................................\n",
      "[CV] ........... batch_size=20, epochs=100, score=0.951, total=   1.9s\n",
      "[CV] batch_size=20, epochs=100 .......................................\n",
      "[CV] ........... batch_size=20, epochs=100, score=0.932, total=   1.9s\n",
      "[CV] batch_size=40, epochs=10 ........................................\n",
      "[CV] ............ batch_size=40, epochs=10, score=1.000, total=   0.6s\n",
      "[CV] batch_size=40, epochs=10 ........................................\n",
      "[CV] ............ batch_size=40, epochs=10, score=0.971, total=   0.6s\n",
      "[CV] batch_size=40, epochs=10 ........................................\n",
      "[CV] ............ batch_size=40, epochs=10, score=0.961, total=   0.6s\n",
      "[CV] batch_size=40, epochs=10 ........................................\n",
      "WARNING:tensorflow:5 out of the last 16 calls to <function Model.make_test_function.<locals>.test_function at 0x0000020457EE10D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV] ............ batch_size=40, epochs=10, score=0.932, total=   0.6s\n",
      "[CV] batch_size=40, epochs=10 ........................................\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x0000020456E06B80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV] ............ batch_size=40, epochs=10, score=0.932, total=   0.6s\n",
      "[CV] batch_size=40, epochs=50 ........................................\n",
      "[CV] ............ batch_size=40, epochs=50, score=1.000, total=   0.9s\n",
      "[CV] batch_size=40, epochs=50 ........................................\n",
      "[CV] ............ batch_size=40, epochs=50, score=0.942, total=   1.3s\n",
      "[CV] batch_size=40, epochs=50 ........................................\n",
      "[CV] ............ batch_size=40, epochs=50, score=0.951, total=   0.9s\n",
      "[CV] batch_size=40, epochs=50 ........................................\n",
      "[CV] ............ batch_size=40, epochs=50, score=0.932, total=   0.9s\n",
      "[CV] batch_size=40, epochs=50 ........................................\n",
      "[CV] ............ batch_size=40, epochs=50, score=0.922, total=   0.9s\n",
      "[CV] batch_size=40, epochs=100 .......................................\n",
      "[CV] ........... batch_size=40, epochs=100, score=1.000, total=   1.3s\n",
      "[CV] batch_size=40, epochs=100 .......................................\n",
      "[CV] ........... batch_size=40, epochs=100, score=0.962, total=   1.2s\n",
      "[CV] batch_size=40, epochs=100 .......................................\n",
      "[CV] ........... batch_size=40, epochs=100, score=0.961, total=   1.3s\n",
      "[CV] batch_size=40, epochs=100 .......................................\n",
      "[CV] ........... batch_size=40, epochs=100, score=0.951, total=   1.3s\n",
      "[CV] batch_size=40, epochs=100 .......................................\n",
      "[CV] ........... batch_size=40, epochs=100, score=0.913, total=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:  1.1min finished\n"
     ]
    }
   ],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=30, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(8, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\\\n",
    "    \n",
    "    adam=Adam(lr=0.01)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "    return model\n",
    "model = KerasClassifier(build_fn = create_model,verbose = 0)\n",
    "# Define the grid search parameters\n",
    "batch_size = [10,20,40]\n",
    "epochs = [10,50,100]\n",
    "# Make a dictionary of the grid search parameters\n",
    "param_grid = dict(batch_size = batch_size,epochs = epochs)\n",
    "# Build and fit the GridSearchCV\n",
    "grid = GridSearchCV(estimator = model,param_grid = param_grid,cv = KFold(),verbose = 10)\n",
    "grid_result = grid.fit(X_standardized,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.9651232242584229, using {'batch_size': 20, 'epochs': 100}\n",
      "0.9535847663879394,0.034134853292367366 with: {'batch_size': 10, 'epochs': 10}\n",
      "0.9593539834022522,0.02620522570533205 with: {'batch_size': 10, 'epochs': 50}\n",
      "0.9651045680046082,0.029202250943530433 with: {'batch_size': 10, 'epochs': 100}\n",
      "0.963181471824646,0.024861122491695094 with: {'batch_size': 20, 'epochs': 10}\n",
      "0.9593166470527649,0.024067069538717917 with: {'batch_size': 20, 'epochs': 50}\n",
      "0.9651232242584229,0.023450336182956687 with: {'batch_size': 20, 'epochs': 100}\n",
      "0.9592793226242066,0.025639116714242988 with: {'batch_size': 40, 'epochs': 10}\n",
      "0.9496265888214112,0.027014153697387244 with: {'batch_size': 40, 'epochs': 50}\n",
      "0.9573562383651734,0.027880119063319796 with: {'batch_size': 40, 'epochs': 100}\n"
     ]
    }
   ],
   "source": [
    "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('{},{} with: {}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout\n",
    "def create_model(learning_rate,dropout_rate):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8,input_dim = 30,kernel_initializer = 'normal',activation = 'relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(4,input_dim = 30,kernel_initializer = 'normal',activation = 'relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1,activation = 'sigmoid'))\n",
    "    \n",
    "    adam = Adam(lr = learning_rate)\n",
    "    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV] dropout_rate=0.0, learning_rate=0.001 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-38fb56cb5200>:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 10)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout_rate=0.0, learning_rate=0.001, score=1.000, total=   0.8s\n",
      "[CV] dropout_rate=0.0, learning_rate=0.001 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout_rate=0.0, learning_rate=0.001, score=0.750, total=   0.6s\n",
      "[CV] dropout_rate=0.0, learning_rate=0.001 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    1.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout_rate=0.0, learning_rate=0.001, score=0.524, total=   0.6s\n",
      "[CV] dropout_rate=0.0, learning_rate=0.001 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    1.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout_rate=0.0, learning_rate=0.001, score=0.680, total=   0.6s\n",
      "[CV] dropout_rate=0.0, learning_rate=0.001 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    2.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout_rate=0.0, learning_rate=0.001, score=0.699, total=   0.6s\n",
      "[CV] dropout_rate=0.0, learning_rate=0.01 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    3.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout_rate=0.0, learning_rate=0.01, score=1.000, total=   0.7s\n",
      "[CV] dropout_rate=0.0, learning_rate=0.01 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    3.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout_rate=0.0, learning_rate=0.01, score=0.981, total=   0.7s\n",
      "[CV] dropout_rate=0.0, learning_rate=0.01 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    4.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout_rate=0.0, learning_rate=0.01, score=0.903, total=   0.6s\n",
      "[CV] dropout_rate=0.0, learning_rate=0.01 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    5.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout_rate=0.0, learning_rate=0.01, score=0.913, total=   0.6s\n",
      "[CV] dropout_rate=0.0, learning_rate=0.01 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    5.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout_rate=0.0, learning_rate=0.01, score=0.874, total=   0.6s\n",
      "[CV] dropout_rate=0.0, learning_rate=0.1 .............................\n",
      "[CV] . dropout_rate=0.0, learning_rate=0.1, score=1.000, total=   0.8s\n",
      "[CV] dropout_rate=0.0, learning_rate=0.1 .............................\n",
      "[CV] . dropout_rate=0.0, learning_rate=0.1, score=0.962, total=   0.6s\n",
      "[CV] dropout_rate=0.0, learning_rate=0.1 .............................\n",
      "[CV] . dropout_rate=0.0, learning_rate=0.1, score=0.981, total=   0.6s\n",
      "[CV] dropout_rate=0.0, learning_rate=0.1 .............................\n",
      "[CV] . dropout_rate=0.0, learning_rate=0.1, score=0.961, total=   0.6s\n",
      "[CV] dropout_rate=0.0, learning_rate=0.1 .............................\n",
      "[CV] . dropout_rate=0.0, learning_rate=0.1, score=0.932, total=   0.6s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.001 ...........................\n",
      "[CV]  dropout_rate=0.1, learning_rate=0.001, score=1.000, total=   0.7s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.001 ...........................\n",
      "[CV]  dropout_rate=0.1, learning_rate=0.001, score=0.788, total=   0.6s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.001 ...........................\n",
      "[CV]  dropout_rate=0.1, learning_rate=0.001, score=0.524, total=   0.6s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.001 ...........................\n",
      "[CV]  dropout_rate=0.1, learning_rate=0.001, score=0.689, total=   0.6s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.001 ...........................\n",
      "[CV]  dropout_rate=0.1, learning_rate=0.001, score=0.699, total=   0.7s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.01 ............................\n",
      "[CV]  dropout_rate=0.1, learning_rate=0.01, score=1.000, total=   0.9s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.01 ............................\n",
      "[CV]  dropout_rate=0.1, learning_rate=0.01, score=0.981, total=   0.7s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.01 ............................\n",
      "[CV]  dropout_rate=0.1, learning_rate=0.01, score=0.971, total=   0.7s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.01 ............................\n",
      "[CV]  dropout_rate=0.1, learning_rate=0.01, score=0.951, total=   0.6s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.01 ............................\n",
      "[CV]  dropout_rate=0.1, learning_rate=0.01, score=0.913, total=   0.6s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.1 .............................\n",
      "[CV] . dropout_rate=0.1, learning_rate=0.1, score=1.000, total=   0.6s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.1 .............................\n",
      "[CV] . dropout_rate=0.1, learning_rate=0.1, score=0.952, total=   0.6s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.1 .............................\n",
      "[CV] . dropout_rate=0.1, learning_rate=0.1, score=0.981, total=   0.7s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.1 .............................\n",
      "[CV] . dropout_rate=0.1, learning_rate=0.1, score=0.942, total=   0.7s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.1 .............................\n",
      "[CV] . dropout_rate=0.1, learning_rate=0.1, score=0.951, total=   0.7s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.001 ...........................\n",
      "[CV]  dropout_rate=0.2, learning_rate=0.001, score=1.000, total=   0.9s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.001 ...........................\n",
      "[CV]  dropout_rate=0.2, learning_rate=0.001, score=0.750, total=   0.6s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.001 ...........................\n",
      "[CV]  dropout_rate=0.2, learning_rate=0.001, score=0.524, total=   0.6s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.001 ...........................\n",
      "[CV]  dropout_rate=0.2, learning_rate=0.001, score=0.680, total=   0.6s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.001 ...........................\n",
      "[CV]  dropout_rate=0.2, learning_rate=0.001, score=0.699, total=   0.6s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.01 ............................\n",
      "[CV]  dropout_rate=0.2, learning_rate=0.01, score=1.000, total=   0.6s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.01 ............................\n",
      "[CV]  dropout_rate=0.2, learning_rate=0.01, score=0.971, total=   0.6s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.01 ............................\n",
      "[CV]  dropout_rate=0.2, learning_rate=0.01, score=0.913, total=   0.7s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.01 ............................\n",
      "[CV]  dropout_rate=0.2, learning_rate=0.01, score=0.951, total=   0.9s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.01 ............................\n",
      "[CV]  dropout_rate=0.2, learning_rate=0.01, score=0.932, total=   0.6s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.1 .............................\n",
      "[CV] . dropout_rate=0.2, learning_rate=0.1, score=1.000, total=   0.7s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.1 .............................\n",
      "[CV] . dropout_rate=0.2, learning_rate=0.1, score=0.923, total=   0.6s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.1 .............................\n",
      "[CV] . dropout_rate=0.2, learning_rate=0.1, score=0.951, total=   0.6s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.1 .............................\n",
      "[CV] . dropout_rate=0.2, learning_rate=0.1, score=0.874, total=   0.6s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.1 .............................\n",
      "[CV] . dropout_rate=0.2, learning_rate=0.1, score=0.913, total=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:   29.8s finished\n"
     ]
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 10)\n",
    "\n",
    "# Define the grid search parameters\n",
    "\n",
    "learning_rate = [0.001,0.01,0.1]\n",
    "dropout_rate = [0.0,0.1,0.2]\n",
    "\n",
    "# Make a dictionary of the grid search parameters\n",
    "\n",
    "param_grids = dict(learning_rate = learning_rate,dropout_rate = dropout_rate)\n",
    "\n",
    "# Build and fit the GridSearchCV\n",
    "\n",
    "grid = GridSearchCV(estimator = model,param_grid = param_grids,cv = KFold(),verbose = 10)\n",
    "grid_result = grid.fit(X_standardized,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.9670649766921997, using {'dropout_rate': 0.0, 'learning_rate': 0.1}\n",
      "0.7305825233459473,0.15435061319000673 with: {'dropout_rate': 0.0, 'learning_rate': 0.001}\n",
      "0.9340179204940796,0.04815082085110961 with: {'dropout_rate': 0.0, 'learning_rate': 0.01}\n",
      "0.9670649766921997,0.022625745131441177 with: {'dropout_rate': 0.0, 'learning_rate': 0.1}\n",
      "0.740216588973999,0.15539238038211267 with: {'dropout_rate': 0.1, 'learning_rate': 0.001}\n",
      "0.9631441354751586,0.029725072856320364 with: {'dropout_rate': 0.1, 'learning_rate': 0.01}\n",
      "0.9651418924331665,0.021738578454537406 with: {'dropout_rate': 0.1, 'learning_rate': 0.1}\n",
      "0.7305825233459473,0.15435061319000673 with: {'dropout_rate': 0.2, 'learning_rate': 0.001}\n",
      "0.9534540772438049,0.030363522966243707 with: {'dropout_rate': 0.2, 'learning_rate': 0.01}\n",
      "0.9321882009506226,0.04206268517874447 with: {'dropout_rate': 0.2, 'learning_rate': 0.1}\n"
     ]
    }
   ],
   "source": [
    "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('{},{} with: {}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(activation_function,init):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8,input_dim = 30,kernel_initializer = init,activation = activation_function))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(4,input_dim = 30,kernel_initializer = init,activation = activation_function))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1,activation = 'sigmoid'))\n",
    "    \n",
    "    adam = Adam(lr = 0.001)\n",
    "    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV] activation_function=softmax, init=uniform .......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-26-71e17feed8ca>:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 10)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=softmax, init=uniform, score=1.000, total=   0.7s\n",
      "[CV] activation_function=softmax, init=uniform .......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=softmax, init=uniform, score=0.750, total=   0.9s\n",
      "[CV] activation_function=softmax, init=uniform .......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    1.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=softmax, init=uniform, score=0.524, total=   0.7s\n",
      "[CV] activation_function=softmax, init=uniform .......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    2.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=softmax, init=uniform, score=0.680, total=   0.7s\n",
      "[CV] activation_function=softmax, init=uniform .......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    2.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=softmax, init=uniform, score=0.699, total=   0.6s\n",
      "[CV] activation_function=softmax, init=normal ........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    3.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=softmax, init=normal, score=1.000, total=   0.7s\n",
      "[CV] activation_function=softmax, init=normal ........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    4.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=softmax, init=normal, score=0.750, total=   0.8s\n",
      "[CV] activation_function=softmax, init=normal ........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    4.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=softmax, init=normal, score=0.524, total=   0.8s\n",
      "[CV] activation_function=softmax, init=normal ........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    5.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=softmax, init=normal, score=0.680, total=   0.7s\n",
      "[CV] activation_function=softmax, init=normal ........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    6.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=softmax, init=normal, score=0.699, total=   0.6s\n",
      "[CV] activation_function=softmax, init=zero ..........................\n",
      "[CV]  activation_function=softmax, init=zero, score=1.000, total=   0.7s\n",
      "[CV] activation_function=softmax, init=zero ..........................\n",
      "[CV]  activation_function=softmax, init=zero, score=0.750, total=   0.9s\n",
      "[CV] activation_function=softmax, init=zero ..........................\n",
      "[CV]  activation_function=softmax, init=zero, score=0.524, total=   0.7s\n",
      "[CV] activation_function=softmax, init=zero ..........................\n",
      "[CV]  activation_function=softmax, init=zero, score=0.320, total=   0.7s\n",
      "[CV] activation_function=softmax, init=zero ..........................\n",
      "[CV]  activation_function=softmax, init=zero, score=0.301, total=   0.7s\n",
      "[CV] activation_function=relu, init=uniform ..........................\n",
      "[CV]  activation_function=relu, init=uniform, score=1.000, total=   0.7s\n",
      "[CV] activation_function=relu, init=uniform ..........................\n",
      "[CV]  activation_function=relu, init=uniform, score=0.750, total=   0.7s\n",
      "[CV] activation_function=relu, init=uniform ..........................\n",
      "[CV]  activation_function=relu, init=uniform, score=0.524, total=   0.6s\n",
      "[CV] activation_function=relu, init=uniform ..........................\n",
      "[CV]  activation_function=relu, init=uniform, score=0.680, total=   0.7s\n",
      "[CV] activation_function=relu, init=uniform ..........................\n",
      "[CV]  activation_function=relu, init=uniform, score=0.699, total=   0.8s\n",
      "[CV] activation_function=relu, init=normal ...........................\n",
      "[CV]  activation_function=relu, init=normal, score=1.000, total=   0.6s\n",
      "[CV] activation_function=relu, init=normal ...........................\n",
      "[CV]  activation_function=relu, init=normal, score=0.904, total=   0.6s\n",
      "[CV] activation_function=relu, init=normal ...........................\n",
      "[CV]  activation_function=relu, init=normal, score=0.524, total=   0.7s\n",
      "[CV] activation_function=relu, init=normal ...........................\n",
      "[CV]  activation_function=relu, init=normal, score=0.680, total=   0.6s\n",
      "[CV] activation_function=relu, init=normal ...........................\n",
      "[CV]  activation_function=relu, init=normal, score=0.709, total=   0.7s\n",
      "[CV] activation_function=relu, init=zero .............................\n",
      "[CV] . activation_function=relu, init=zero, score=1.000, total=   0.6s\n",
      "[CV] activation_function=relu, init=zero .............................\n",
      "[CV] . activation_function=relu, init=zero, score=0.750, total=   0.6s\n",
      "[CV] activation_function=relu, init=zero .............................\n",
      "[CV] . activation_function=relu, init=zero, score=0.524, total=   0.6s\n",
      "[CV] activation_function=relu, init=zero .............................\n",
      "[CV] . activation_function=relu, init=zero, score=0.680, total=   0.7s\n",
      "[CV] activation_function=relu, init=zero .............................\n",
      "[CV] . activation_function=relu, init=zero, score=0.699, total=   0.9s\n",
      "[CV] activation_function=tanh, init=uniform ..........................\n",
      "[CV]  activation_function=tanh, init=uniform, score=1.000, total=   0.7s\n",
      "[CV] activation_function=tanh, init=uniform ..........................\n",
      "[CV]  activation_function=tanh, init=uniform, score=0.788, total=   0.6s\n",
      "[CV] activation_function=tanh, init=uniform ..........................\n",
      "[CV]  activation_function=tanh, init=uniform, score=0.709, total=   0.7s\n",
      "[CV] activation_function=tanh, init=uniform ..........................\n",
      "[CV]  activation_function=tanh, init=uniform, score=0.854, total=   0.7s\n",
      "[CV] activation_function=tanh, init=uniform ..........................\n",
      "[CV]  activation_function=tanh, init=uniform, score=0.845, total=   0.7s\n",
      "[CV] activation_function=tanh, init=normal ...........................\n",
      "[CV]  activation_function=tanh, init=normal, score=0.933, total=   0.6s\n",
      "[CV] activation_function=tanh, init=normal ...........................\n",
      "[CV]  activation_function=tanh, init=normal, score=0.808, total=   0.6s\n",
      "[CV] activation_function=tanh, init=normal ...........................\n",
      "[CV]  activation_function=tanh, init=normal, score=0.786, total=   0.8s\n",
      "[CV] activation_function=tanh, init=normal ...........................\n",
      "[CV]  activation_function=tanh, init=normal, score=0.845, total=   0.6s\n",
      "[CV] activation_function=tanh, init=normal ...........................\n",
      "[CV]  activation_function=tanh, init=normal, score=0.816, total=   0.6s\n",
      "[CV] activation_function=tanh, init=zero .............................\n",
      "[CV] . activation_function=tanh, init=zero, score=1.000, total=   0.6s\n",
      "[CV] activation_function=tanh, init=zero .............................\n",
      "[CV] . activation_function=tanh, init=zero, score=0.750, total=   0.7s\n",
      "[CV] activation_function=tanh, init=zero .............................\n",
      "[CV] . activation_function=tanh, init=zero, score=0.524, total=   0.7s\n",
      "[CV] activation_function=tanh, init=zero .............................\n",
      "[CV] . activation_function=tanh, init=zero, score=0.680, total=   0.6s\n",
      "[CV] activation_function=tanh, init=zero .............................\n",
      "[CV] . activation_function=tanh, init=zero, score=0.699, total=   0.6s\n",
      "[CV] activation_function=linear, init=uniform ........................\n",
      "[CV]  activation_function=linear, init=uniform, score=0.990, total=   0.6s\n",
      "[CV] activation_function=linear, init=uniform ........................\n",
      "[CV]  activation_function=linear, init=uniform, score=0.798, total=   0.6s\n",
      "[CV] activation_function=linear, init=uniform ........................\n",
      "[CV]  activation_function=linear, init=uniform, score=0.738, total=   0.8s\n",
      "[CV] activation_function=linear, init=uniform ........................\n",
      "[CV]  activation_function=linear, init=uniform, score=0.893, total=   0.7s\n",
      "[CV] activation_function=linear, init=uniform ........................\n",
      "[CV]  activation_function=linear, init=uniform, score=0.825, total=   0.6s\n",
      "[CV] activation_function=linear, init=normal .........................\n",
      "[CV]  activation_function=linear, init=normal, score=0.981, total=   0.6s\n",
      "[CV] activation_function=linear, init=normal .........................\n",
      "[CV]  activation_function=linear, init=normal, score=0.798, total=   0.6s\n",
      "[CV] activation_function=linear, init=normal .........................\n",
      "[CV]  activation_function=linear, init=normal, score=0.728, total=   0.6s\n",
      "[CV] activation_function=linear, init=normal .........................\n",
      "[CV]  activation_function=linear, init=normal, score=0.854, total=   0.6s\n",
      "[CV] activation_function=linear, init=normal .........................\n",
      "[CV]  activation_function=linear, init=normal, score=0.874, total=   0.7s\n",
      "[CV] activation_function=linear, init=zero ...........................\n",
      "[CV]  activation_function=linear, init=zero, score=1.000, total=   0.7s\n",
      "[CV] activation_function=linear, init=zero ...........................\n",
      "[CV]  activation_function=linear, init=zero, score=0.750, total=   0.8s\n",
      "[CV] activation_function=linear, init=zero ...........................\n",
      "[CV]  activation_function=linear, init=zero, score=0.524, total=   0.6s\n",
      "[CV] activation_function=linear, init=zero ...........................\n",
      "[CV]  activation_function=linear, init=zero, score=0.680, total=   0.7s\n",
      "[CV] activation_function=linear, init=zero ...........................\n",
      "[CV]  activation_function=linear, init=zero, score=0.699, total=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:   40.8s finished\n"
     ]
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 10)\n",
    "\n",
    "# Define the grid search parameters\n",
    "activation_function = ['softmax','relu','tanh','linear']\n",
    "init = ['uniform','normal','zero']\n",
    "\n",
    "# Make a dictionary of the grid search parameters\n",
    "param_grids = dict(activation_function = activation_function,init = init)\n",
    "\n",
    "# Build and fit the GridSearchCV\n",
    "\n",
    "grid = GridSearchCV(estimator = model,param_grid = param_grids,cv = KFold(),verbose = 10)\n",
    "grid_result = grid.fit(X_standardized,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.848954439163208, using {'activation_function': 'linear', 'init': 'uniform'}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'softmax', 'init': 'uniform'}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'softmax', 'init': 'normal'}\n",
      "0.5791262149810791,0.26595385640371694 with: {'activation_function': 'softmax', 'init': 'zero'}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'relu', 'init': 'uniform'}\n",
      "0.7632934927940369,0.1690534469641404 with: {'activation_function': 'relu', 'init': 'normal'}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'relu', 'init': 'zero'}\n",
      "0.8392457127571106,0.0956151673023234 with: {'activation_function': 'tanh', 'init': 'uniform'}\n",
      "0.8373973131179809,0.05117462080853216 with: {'activation_function': 'tanh', 'init': 'normal'}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'tanh', 'init': 'zero'}\n",
      "0.848954439163208,0.08654749953094734 with: {'activation_function': 'linear', 'init': 'uniform'}\n",
      "0.8470313549041748,0.08388508379948657 with: {'activation_function': 'linear', 'init': 'normal'}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'linear', 'init': 'zero'}\n"
     ]
    }
   ],
   "source": [
    "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('{},{} with: {}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(neuron1,neuron2):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neuron1,input_dim = 30,kernel_initializer = 'uniform',activation = 'tanh'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(neuron2,input_dim = neuron1,kernel_initializer = 'uniform',activation = 'tanh'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1,activation = 'sigmoid'))\n",
    "    \n",
    "    adam = Adam(lr = 0.001)\n",
    "    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV] neuron1=4, neuron2=2 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-29-67fe63bd7fd4>:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 10)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ neuron1=4, neuron2=2, score=1.000, total=   0.6s\n",
      "[CV] neuron1=4, neuron2=2 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ neuron1=4, neuron2=2, score=0.750, total=   0.7s\n",
      "[CV] neuron1=4, neuron2=2 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    1.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ neuron1=4, neuron2=2, score=0.583, total=   0.7s\n",
      "[CV] neuron1=4, neuron2=2 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    1.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ neuron1=4, neuron2=2, score=0.728, total=   0.7s\n",
      "[CV] neuron1=4, neuron2=2 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    2.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ neuron1=4, neuron2=2, score=0.689, total=   0.6s\n",
      "[CV] neuron1=4, neuron2=4 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    3.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ neuron1=4, neuron2=4, score=1.000, total=   0.8s\n",
      "[CV] neuron1=4, neuron2=4 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    4.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ neuron1=4, neuron2=4, score=0.750, total=   0.6s\n",
      "[CV] neuron1=4, neuron2=4 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    4.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ neuron1=4, neuron2=4, score=0.631, total=   0.6s\n",
      "[CV] neuron1=4, neuron2=4 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    5.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ neuron1=4, neuron2=4, score=0.767, total=   0.6s\n",
      "[CV] neuron1=4, neuron2=4 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    6.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ neuron1=4, neuron2=4, score=0.680, total=   0.6s\n",
      "[CV] neuron1=4, neuron2=8 ............................................\n",
      "[CV] ................ neuron1=4, neuron2=8, score=1.000, total=   0.6s\n",
      "[CV] neuron1=4, neuron2=8 ............................................\n",
      "[CV] ................ neuron1=4, neuron2=8, score=0.750, total=   0.6s\n",
      "[CV] neuron1=4, neuron2=8 ............................................\n",
      "[CV] ................ neuron1=4, neuron2=8, score=0.631, total=   0.7s\n",
      "[CV] neuron1=4, neuron2=8 ............................................\n",
      "[CV] ................ neuron1=4, neuron2=8, score=0.777, total=   0.6s\n",
      "[CV] neuron1=4, neuron2=8 ............................................\n",
      "[CV] ................ neuron1=4, neuron2=8, score=0.709, total=   0.8s\n",
      "[CV] neuron1=8, neuron2=2 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=2, score=0.990, total=   0.7s\n",
      "[CV] neuron1=8, neuron2=2 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=2, score=0.769, total=   0.7s\n",
      "[CV] neuron1=8, neuron2=2 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=2, score=0.699, total=   0.8s\n",
      "[CV] neuron1=8, neuron2=2 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=2, score=0.786, total=   0.6s\n",
      "[CV] neuron1=8, neuron2=2 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=2, score=0.816, total=   0.6s\n",
      "[CV] neuron1=8, neuron2=4 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=4, score=1.000, total=   0.6s\n",
      "[CV] neuron1=8, neuron2=4 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=4, score=0.788, total=   0.6s\n",
      "[CV] neuron1=8, neuron2=4 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=4, score=0.777, total=   0.6s\n",
      "[CV] neuron1=8, neuron2=4 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=4, score=0.845, total=   0.7s\n",
      "[CV] neuron1=8, neuron2=4 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=4, score=0.816, total=   0.8s\n",
      "[CV] neuron1=8, neuron2=8 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=8, score=1.000, total=   0.7s\n",
      "[CV] neuron1=8, neuron2=8 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=8, score=0.827, total=   0.6s\n",
      "[CV] neuron1=8, neuron2=8 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=8, score=0.806, total=   0.7s\n",
      "[CV] neuron1=8, neuron2=8 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=8, score=0.864, total=   0.7s\n",
      "[CV] neuron1=8, neuron2=8 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=8, score=0.864, total=   0.6s\n",
      "[CV] neuron1=16, neuron2=2 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=2, score=0.990, total=   0.6s\n",
      "[CV] neuron1=16, neuron2=2 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=2, score=0.827, total=   0.7s\n",
      "[CV] neuron1=16, neuron2=2 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=2, score=0.835, total=   0.6s\n",
      "[CV] neuron1=16, neuron2=2 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=2, score=0.893, total=   0.8s\n",
      "[CV] neuron1=16, neuron2=2 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=2, score=0.786, total=   0.7s\n",
      "[CV] neuron1=16, neuron2=4 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=4, score=1.000, total=   0.6s\n",
      "[CV] neuron1=16, neuron2=4 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=4, score=0.865, total=   0.7s\n",
      "[CV] neuron1=16, neuron2=4 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=4, score=0.864, total=   0.6s\n",
      "[CV] neuron1=16, neuron2=4 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=4, score=0.903, total=   0.6s\n",
      "[CV] neuron1=16, neuron2=4 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=4, score=0.864, total=   0.7s\n",
      "[CV] neuron1=16, neuron2=8 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=8, score=1.000, total=   0.7s\n",
      "[CV] neuron1=16, neuron2=8 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=8, score=0.865, total=   0.7s\n",
      "[CV] neuron1=16, neuron2=8 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=8, score=0.845, total=   0.6s\n",
      "[CV] neuron1=16, neuron2=8 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=8, score=0.913, total=   0.9s\n",
      "[CV] neuron1=16, neuron2=8 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=8, score=0.883, total=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:   30.3s finished\n"
     ]
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 10)\n",
    "\n",
    "# Define the grid search parameters\n",
    "\n",
    "neuron1 = [4,8,16]\n",
    "neuron2 = [2,4,8]\n",
    "\n",
    "# Make a dictionary of the grid search parameters\n",
    "\n",
    "param_grids = dict(neuron1 = neuron1,neuron2 = neuron2)\n",
    "\n",
    "# Build and fit the GridSearchCV\n",
    "\n",
    "grid = GridSearchCV(estimator = model,param_grid = param_grids,cv = KFold(),verbose = 10)\n",
    "grid_result = grid.fit(X_standardized,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.9012322783470154, using {'neuron1': 16, 'neuron2': 8}\n",
      "0.75,0.13762798850857494 with: {'neuron1': 4, 'neuron2': 2}\n",
      "0.7655339717864991,0.12702874437720252 with: {'neuron1': 4, 'neuron2': 4}\n",
      "0.7733009576797485,0.12356825295820398 with: {'neuron1': 4, 'neuron2': 8}\n",
      "0.8121172666549683,0.09703615951230277 with: {'neuron1': 8, 'neuron2': 2}\n",
      "0.8450709581375122,0.08093819359822489 with: {'neuron1': 8, 'neuron2': 4}\n",
      "0.8721807360649109,0.06770582232672971 with: {'neuron1': 8, 'neuron2': 8}\n",
      "0.866374158859253,0.07076274350869129 with: {'neuron1': 16, 'neuron2': 2}\n",
      "0.8992905259132385,0.05250717082163245 with: {'neuron1': 16, 'neuron2': 4}\n",
      "0.9012322783470154,0.054193783589354935 with: {'neuron1': 16, 'neuron2': 8}\n"
     ]
    }
   ],
   "source": [
    "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('{},{} with: {}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(16,input_dim = 30,kernel_initializer = 'normal',activation = 'linear'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(8,input_dim = 30,kernel_initializer = 'normal',activation = 'linear'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1,activation = 'linear'))\n",
    "    \n",
    "    adam = Adam(lr = 0.01) #sgd = SGD(lr=learning_rate, momentum=momentum, decay=decay_rate, nesterov=False)\n",
    "    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-32-a3b0550f7bfa>:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9787234042553191\n"
     ]
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 100)\n",
    "\n",
    "# Fitting the model\n",
    "\n",
    "model.fit(X_standardized,y)\n",
    "\n",
    "# Predicting using trained model\n",
    "\n",
    "y_predict = model.predict(X_standardized)\n",
    "\n",
    "# Printing the metrics\n",
    "print(accuracy_score(y,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
